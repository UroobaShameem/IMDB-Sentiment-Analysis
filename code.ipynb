{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB Movies Reviews SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "data= pd.read_csv(\"dataset/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print first five rows of dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       False\n",
       "sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tokens= ToktokTokenizer()\n",
    "stopwords= nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### noise removal\n",
    "using BeautifulSoup for removing any html tags that might be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25356\\1029199373.py:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "  text = re.sub('\\[[^]]*\\]', '', text)\n"
     ]
    }
   ],
   "source": [
    "# noise removal\n",
    "def noise_removal(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25356\\1029199373.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "data['review'] = data['review'].apply(noise_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other review ha mention that after ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonder littl production. the film techniqu i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought thi wa a wonder way to spend time on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there' a famili where a littl boy (jake)...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei' \"love in the time of money\" is ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other review ha mention that after ...  positive\n",
       "1  a wonder littl production. the film techniqu i...  positive\n",
       "2  i thought thi wa a wonder way to spend time on...  positive\n",
       "3  basic there' a famili where a littl boy (jake)...  negative\n",
       "4  petter mattei' \"love in the time of money\" is ...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if stemming is done\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'been', 'him', 'which', 'so', \"couldn't\", 'being', 'under', 'into', \"you've\", \"she's\", 'not', 'whom', 'having', 'when', 'few', 'it', 'further', 't', 'why', \"you'd\", 'was', 'should', 'for', 'your', 'herself', 'their', 'those', 'i', 'yours', 'during', 'after', \"didn't\", 'hasn', \"hadn't\", 'isn', 'a', 'am', 'mightn', 'only', \"should've\", 'nor', 'my', \"isn't\", 'mustn', 'needn', 'y', 'on', 'she', 'at', 'doing', 'what', 'out', 'but', 'ain', \"you'll\", 'this', 'didn', 'no', 'the', \"aren't\", 'ma', 'again', 'own', 'couldn', 'her', 'now', \"needn't\", 've', 'once', 'some', 'do', 'yourself', 'has', 'of', 'were', 'if', 'most', 'haven', 'down', \"hasn't\", 'theirs', 'our', 'and', 'while', 'how', 'up', \"weren't\", 'can', 'be', \"doesn't\", \"mustn't\", 'doesn', 'wouldn', 'himself', 'each', 'hadn', 'll', 'from', 'won', 'have', 'aren', 'until', 'its', 'ourselves', 'we', 'between', 'they', 'here', 'm', 'shan', 'weren', 'does', 'd', \"wasn't\", 'against', 'all', \"don't\", 'where', 'such', 'wasn', \"mightn't\", 'me', \"you're\", 'through', 'there', 'will', 'ours', 'more', 'are', 'any', 'hers', 'other', 'just', 'below', 'or', 'by', 'then', 'them', 'these', 'same', 'he', 'an', 'as', 'themselves', \"won't\", 'o', 'had', 'both', 'than', 'over', 'myself', 'very', 'with', 'too', \"shouldn't\", 'off', \"shan't\", \"haven't\", 'his', 're', \"it's\", 'yourselves', 'shouldn', 'who', 's', 'that', 'because', 'before', 'did', 'above', 'don', 'you', 'is', 'about', \"wouldn't\", \"that'll\", 'in', 'to', 'itself'}\n"
     ]
    }
   ],
   "source": [
    "# set stop words to English\n",
    "stop_wr=set(stopwords.words('english'))\n",
    "print(stop_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords\n",
    "def removing_stopwords(text, is_lower_case=False):  #set lower case flag to false \n",
    "    #Tokenization of text\n",
    "    tokenizers=ToktokTokenizer()\n",
    "    #Setting English stopwords\n",
    "    tokens = tokenizers.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]    #remove whitespace\n",
    "    if is_lower_case:\n",
    "        filter_tokens = [token for token in tokens if token not in stop_wr] #if text in lowercase then compare to stopwords\n",
    "    else:\n",
    "        filter_tokens = [token for token in tokens if token.lower() not in stop_wr] #if not in lowercase then convert and compare\n",
    "    filtered_text = ' '.join(filter_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch 1 oz episod ' hook...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl production. film techniqu veri un...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic ' famili littl boy ( jake ) think ' zomb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei ' \" love time money \" visual stu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one review ha mention watch 1 oz episod ' hook...  positive\n",
       "1  wonder littl production. film techniqu veri un...  positive\n",
       "2  thought thi wa wonder way spend time hot summe...  positive\n",
       "3  basic ' famili littl boy ( jake ) think ' zomb...  negative\n",
       "4  petter mattei ' \" love time money \" visual stu...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset\n",
    "splitting dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainig dataset\n",
    "training_data = data.review[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing dataset\n",
    "testing_data= data.review[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (30000, 4954557)\n",
      "BOW_cv_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=1,max_df=1,binary=False,ngram_range=(1,3))\n",
    "\n",
    "#transformed train reviews\n",
    "cv_train=cv.fit_transform(training_data)\n",
    "\n",
    "#transformed test reviews\n",
    "cv_test=cv.transform(testing_data)\n",
    "\n",
    "print('BOW_cv_train:',cv_train.shape)\n",
    "print('BOW_cv_test:',cv_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cv=CountVectorizer(min_df=1,max_df=1,binary=False,ngram_range=(1,3))\n",
    "min_df=1 means the term must appear in at least 1 document to be included.\n",
    "max_df=1 means the term must appear in at most 1 document to be included.\n",
    "binary=False: This indicates that the vectorizer will count the frequency of words, rather than marking presence/absence of words with 1 and 0.\n",
    "ngram_range=(1,3) means that the vectorizer will consider unigrams, bigrams and trigrams.\n",
    "##### cv_train=cv.fit_transform(training_data)\n",
    "fit: The vectorizer learns the vocabulary from the training_data (i.e., the words and their counts).\n",
    "transform: Transforms the training_data into a matrix of token counts (Bag of Words matrix).\n",
    "##### cv_test=cv.transform(testing_data)\n",
    "This applies the vocabulary learned from the training data to the testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF\n",
    "This vectorizer converts text documents into a matrix of TF-IDF features. TF-IDF is a weighting method that combines two factors:\n",
    "Term Frequency (TF): How frequently a word appears in a document.\n",
    "Inverse Document Frequency (IDF): Measures how rare a word is across all documents (downweights common words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (30000, 4954557)\n",
      "Tfidf_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(min_df=1,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "\n",
    "#transformed train reviews\n",
    "tf_train=tf.fit_transform(training_data)\n",
    "\n",
    "#transformed test reviews\n",
    "tf_test=tf.transform(testing_data)\n",
    "\n",
    "print('Tfidf_train:',tf_train.shape)\n",
    "print('Tfidf_test:',tf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling\n",
    "convert categorical sentiment data (\"positive\", \"negative\") into a binary numerical format, where each label is represented as 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "label=LabelBinarizer()\n",
    "\n",
    "#transformed sentiment data\n",
    "sentiment_data=label.fit_transform(data['sentiment'])\n",
    "\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= data.sentiment[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= data.sentiment[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "logistic=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=logistic.fit(cv_train,train_data)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=logistic.fit(tf_train,train_data)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=logistic.predict(cv_test)\n",
    "print(lr_bow_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=logistic.predict(tf_test)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.7428\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_data,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.743\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_data,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
